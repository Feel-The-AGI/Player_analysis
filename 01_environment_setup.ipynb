{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GT AI Talent Acquisition Project Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "The GT AI Talent Acquisition Project Management is gathering a team to embark on an AI project to develop a model to make accurate predictions for a football games. This notebook details the processes developed for loading data to peforming analysis.\n",
    "\n",
    "In this notebbok the roles of the data engineer and data scientist are outlined for further development and for documenation purposes. For this particular project, The DFL - Bundesliga Data Shootout Kaggle Competition shall be used to kick-start the project and enable team members prep and familiarize themselves with how the real work would look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Ingestion**\n",
    "\n",
    "The Data Ingestion role characterizes everything that is done to load and extract data from various sources to be stored in an efficient storage system. This section would detail how the football game videos were loaded from Kaggle (in this case, this is out target source).\n",
    "\n",
    "### **Libraries and Packages**\n",
    "\n",
    "\n",
    "**Kaggle :** This packgae had to be installed to facilitate a direct download from Kaggle to the preferred cloud storage, which for this project (due to external issues), is Google drive. So in the script below 'kaggle' is installed and in the following script 'KaggleApi' is imported from the 'kaggle.api.kaggle_api_extended' library to handle the api set up and thus facilitate direct link to the required data.\n",
    "\n",
    "**OS :** This Python module was used used to execute file system functionalities. For this project it is used to crest directories, navigate through file systems, remove unwanted files and rename files or directores.\n",
    "\n",
    "**CV2 :** This is from the 'OpenCV' package to handle reading video files.\n",
    "\n",
    "**ZipFile :** This Python module facilitates CRUD functionalites on zip files. For this project, it was used to locate the zip files in the Kaggle storage as the videos were zip files. This module is also used to extraxt zip files to have the raw video format.\n",
    "\n",
    "\n",
    "\n",
    "### **Data Ingestion Procedures and Steps**\n",
    "\n",
    "**Importing Libraries and Packges :** This first step is to import libraries and packages. For this project the libraries as stated in the 'Libraries and Packages section were imported'. Kaggle is also downloaded using pip.\n",
    "\n",
    "**Defining Functions to List Files in Kaggle :** A function called 'list_files_in_kaggle_competition' is defined to view the available data from the source and decide which data shall be used. This also helped with confirming Kaggle API connection. This function returns a list of files in the Kaggle dates set defined. These functionalities are peformed within this function;\n",
    "\n",
    "- **Initialising Kaggle** is done here using the 'KaggleApi' instance.\n",
    "- **List files in the Kaggle dataset** in order to view the available files in the dataset and their formats. This also ensures successful API connection and initialization.  \n",
    "\n",
    "**Defining Function to download Dta from Kaggle to Google Drive :** This function ensures that the files defined in it's parameters are downloaded into the defined path. These functionalities are peformed within this function;\n",
    "\n",
    "- **Initialising Kaggle** is done here using the 'KaggleApi' instance.\n",
    "- **Ensuring the Download Path Exist** as provided in the parameter.  \n",
    "- **Download Specific Files** since the entire data is large, only the train and test folders along with the train CSV file were to be used.\n",
    "- **Extract Zip files** in order to acquire the video data. Files were stored as zip files in Kaggle, so this is necessary to ensure data can be used effectively.\n",
    "\n",
    "\n",
    "** Set Kaggle Credentials :** Kaggle credentials is set using 'os.environ' to set it as enviroment variables to authenticate with the Kaggle API.\n",
    "\n",
    "**List All the Files in the Kaggel dataset :** By calling the 'list_files_in_kaggle_competition' function to retrieve and print the names of all files available in the specified Kaggle competition.\n",
    "\n",
    "**Specify the files to download :** The files to download are specified. It includes the train.csv file explicitly and all files in the train and test directories.\n",
    "\n",
    "**Download data into specified directory :** By calling the 'download_specific_files_kaggle' function, the files specified are to be downloaded into the specifed google drive path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def list_files_in_kaggle_competition(competition: str):\n",
    "    # Initializing Kaggle API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    # List Kaggle DFL files\n",
    "    files = api.competition_list_files(competition)\n",
    "    return files.files  \n",
    "\n",
    "def download_specific_files_kaggle(competition: str, files_to_download: list, download_path: str):\n",
    "    # Initializing Kaggle API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    # Ensure the download path exists\n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)\n",
    "\n",
    "    # Download specific files\n",
    "    for file_name in files_to_download:\n",
    "        file_path = os.path.join(download_path, file_name)\n",
    "        print(f\"Attempting to download {file_name} to {file_path}\")  # Debug statement\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"File {file_name} already exists. Skipping download.\")\n",
    "            continue\n",
    "        try:\n",
    "            # Ensure subdirectories are created\n",
    "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "            api.competition_download_file(competition, file_name, path=download_path)\n",
    "            print(f\"Downloaded {file_name} to {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {file_name}: {e}\")\n",
    "\n",
    "def extract_zip_files(directory):\n",
    "    # Extract all zip files, including nested zips\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(root)\n",
    "                    os.remove(file_path)  # Optionally, remove the zip file after extraction\n",
    "                    print(f\"Extracted {file_path}\")\n",
    "                    # Recursively extract any new zips\n",
    "                    extract_zip_files(root)\n",
    "                except zipfile.BadZipFile:\n",
    "                    print(f\"Bad zip file: {file_path}\")\n",
    "\n",
    "def check_video_files(directory):\n",
    "    all_videos_valid = True\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                video_path = os.path.join(root, file)\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                if not cap.isOpened():\n",
    "                    print(f\"Corrupt video file detected: {video_path}\")\n",
    "                    all_videos_valid = False\n",
    "                cap.release()\n",
    "    if all_videos_valid:\n",
    "        print(\"All video files are valid and not corrupt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/mydrive')\n",
    "\n",
    "# import os\n",
    "# import boto3\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# # AWS Credentials\n",
    "# os.environ['AWS_ACCESS_KEY_ID'] = 'your_access_key'\n",
    "# os.environ['AWS_SECRET_ACCESS_KEY'] = 'your_secret_key'\n",
    "# os.environ['AWS_DEFAULT_REGION'] = 'your_region'\n",
    "\n",
    "# # Kaggle Credentials\n",
    "# os.environ['KAGGLE_USERNAME'] = 'your_kaggle_username'\n",
    "# os.environ['KAGGLE_KEY'] = 'your_kaggle_key'\n",
    "\n",
    "# def download_dataset(dataset_name, path_to_save):\n",
    "#     api = KaggleApi()\n",
    "#     api.authenticate()\n",
    "#     api.dataset_download_files(dataset_name, path=path_to_save, unzip=True)\n",
    "\n",
    "# def upload_files_to_s3(bucket_name, source_folder, s3_folder):\n",
    "#     s3 = boto3.client('s3')\n",
    "#     for filename in os.listdir(source_folder):\n",
    "#         local_path = os.path.join(source_folder, filename)\n",
    "#         s3_path = os.path.join(s3_folder, filename)\n",
    "#         s3.upload_file(local_path, bucket_name, s3_path)\n",
    "#         print(f\"Uploaded {filename} to s3://{bucket_name}/{s3_path}\")\n",
    "\n",
    "# # Download from Kaggle\n",
    "# download_dataset('dataset-owner/dataset-name', './data')\n",
    "\n",
    "# # Upload to S3\n",
    "# upload_files_to_s3('your-s3-bucket', './data', 'kaggle-data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/0b1495d3_1.mp4\n",
      "test/9f4df856_0.mp4\n",
      "test/2f54ed1c_1.mp4\n",
      "test/947e05ca_0.mp4\n",
      "test/160606be_0.mp4\n",
      "test/9a70c54e_1.mp4\n",
      "test/2f54ed1c_0.mp4\n",
      "test/947e05ca_1.mp4\n",
      "test/9a70c54e_0.mp4\n",
      "test/4dae79a9_0.mp4\n",
      "test/019d5b34_0.mp4\n",
      "test/9d3c239b_0.mp4\n",
      "test/5dc4fe12_0.mp4\n",
      "test/4dae79a9_1.mp4\n",
      "test/0b1495d3_0.mp4\n",
      "test/019d5b34_1.mp4\n",
      "test/9d3c239b_1.mp4\n",
      "test/9f4df856_1.mp4\n",
      "test/5dc4fe12_1.mp4\n",
      "test/160606be_1.mp4\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE REAL ONE\n",
    "\n",
    "# RUN TO LOAD DATA\n",
    "\n",
    "# Set Kaggle API credentials\n",
    "os.environ['KAGGLE_USERNAME'] = 'yolenedeblanche'\n",
    "os.environ['KAGGLE_KEY'] = '38868207cd31f4b0b736846cfe41c7c3'\n",
    "\n",
    "# List all files in the competition to view files in DFL and check API connection\n",
    "files = list_files_in_kaggle_competition('dfl-bundesliga-data-shootout')\n",
    "for file in files:\n",
    "    print(file.name)\n",
    "\n",
    "# Initialize train.csv file to download\n",
    "files_to_download = ['train.csv']\n",
    "\n",
    "# Adding all files in 'train' and 'test' directories\n",
    "train_files_to_download = [file.name for file in files if file.name.startswith('train/')]\n",
    "test_files_to_download = [file.name for file in files if file.name.startswith('test/')]\n",
    "\n",
    "# Debug statements to verify the files to be downloaded\n",
    "print(\"Files to download (train):\", train_files_to_download)\n",
    "print(\"Files to download (test):\", test_files_to_download)\n",
    "\n",
    "# Download the specific files and directories, i.e., the data\n",
    "download_path = '/content/drive/MyDrive/GT-Bungladesh/raw_data_kaggle'\n",
    "train_download_path = os.path.join(download_path, 'train')\n",
    "test_download_path = os.path.join(download_path, 'test')\n",
    "\n",
    "# Create train and test directories\n",
    "os.makedirs(train_download_path, exist_ok=True)\n",
    "os.makedirs(test_download_path, exist_ok=True)\n",
    "\n",
    "# Download train.csv file to the main directory\n",
    "download_specific_files_kaggle('dfl-bundesliga-data-shootout', ['train.csv'], download_path)\n",
    "\n",
    "# Download train files to the train directory\n",
    "download_specific_files_kaggle('dfl-bundesliga-data-shootout', train_files_to_download, download_path=train_download_path)\n",
    "\n",
    "# Download test files to the test directory\n",
    "download_specific_files_kaggle('dfl-bundesliga-data-shootout', test_files_to_download, download_path=test_download_path)\n",
    "\n",
    "# Print to check if files are downloaded correctly\n",
    "print(f\"Train files downloaded to: {train_download_path}\")\n",
    "print(f\"Test files downloaded to: {test_download_path}\")\n",
    "\n",
    "# Extract all downloaded zip files\n",
    "extract_zip_files(train_download_path)\n",
    "# extract_zip_files(test_download_path)\n",
    "\n",
    "# Check for corrupt video files\n",
    "check_video_files(train_download_path)\n",
    "check_video_files(test_download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to save the data in AWS S3 Bucket. Until that issue is fixed, here are the codes for preprocessing. It has been tested and it works when we have the data locally. Figuring out how it will work when the data is in S3 shouldn't be too hard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_frames_from_video\u001b[39m(video_path, output_folder):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Create a VideoCapture object to read from video file\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames_from_video(video_path, output_folder):\n",
    "    # Create a VideoCapture object to read from video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # if no more frames to read\n",
    "\n",
    "        # Save each frame as a JPEG file\n",
    "        frame_filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Finished extracting frames from {video_path}\")\n",
    "\n",
    "def process_videos_in_folder(folder_path):\n",
    "    # List all files in the given folder\n",
    "    for entry in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, entry)\n",
    "        # Check if the file is a video (you could check extensions like .mp4, .avi)\n",
    "        if os.path.isfile(file_path) and file_path.endswith('.mp4'):\n",
    "            # Create a subfolder for the frames of this video\n",
    "            video_name = os.path.splitext(entry)[0]\n",
    "            frames_output_folder = os.path.join(folder_path, video_name + '_frames')\n",
    "            os.makedirs(frames_output_folder, exist_ok=True)\n",
    "\n",
    "            # Extract frames\n",
    "            extract_frames_from_video(file_path, frames_output_folder)\n",
    "\n",
    "# Set the directory where your videos are located\n",
    "video_directory = '/content/raw_data/test'  # Adjust this path to fit video files location\n",
    "\n",
    "# Process all videos in the directory\n",
    "process_videos_in_folder(video_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you want to overwrite the frames in the orginal extracted frames with the resize frames\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def resize_frames_in_folder(folder_path, width=640, height=480):\n",
    "    \"\"\"Resize all frames in a specified folder.\"\"\"\n",
    "    for entry in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, entry)\n",
    "        if file_path.endswith('.jpg'):\n",
    "            # Read the frame\n",
    "            frame = cv2.imread(file_path)\n",
    "            # Resize the frame\n",
    "            resized_frame = cv2.resize(frame, (width, height))\n",
    "            # Save the resized frame\n",
    "            cv2.imwrite(file_path, resized_frame)\n",
    "            print(f\"Resized and saved {file_path}\")\n",
    "\n",
    "def process_multiple_folders(parent_folder):\n",
    "    \"\"\"Process each subfolder within a parent directory.\"\"\"\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
    "            print(f\"Processing folder: {folder_path}\")\n",
    "            resize_frames_in_folder(folder_path)\n",
    "\n",
    "# Example usage\n",
    "parent_folder = '/path/to/your/parent/directory'  # Adjust this path to fit video files location where multiple frames folders are stored\n",
    "process_multiple_folders(parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you want the resized frames to be saved seperately\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def resize_frames_in_folder(folder_path, width=640, height=480):\n",
    "    \"\"\"Resize all frames in a specified folder and save them in a subfolder.\"\"\"\n",
    "    # Create a subfolder for the resized frames\n",
    "    resized_folder_path = os.path.join(folder_path, 'resized')\n",
    "    if not os.path.exists(resized_folder_path):\n",
    "        os.makedirs(resized_folder_path)\n",
    "\n",
    "    for entry in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, entry)\n",
    "        if file_path.endswith('.jpg'):\n",
    "            # Read the frame\n",
    "            frame = cv2.imread(file_path)\n",
    "            # Resize the frame\n",
    "            resized_frame = cv2.resize(frame, (width, height))\n",
    "            # Save the resized frame in the new subfolder\n",
    "            resized_file_path = os.path.join(resized_folder_path, entry)\n",
    "            cv2.imwrite(resized_file_path, resized_frame)\n",
    "            print(f\"Resized and saved {resized_file_path}\")\n",
    "\n",
    "def process_multiple_folders(parent_folder):\n",
    "    \"\"\"Process each subfolder within a parent directory.\"\"\"\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
    "            print(f\"Processing folder: {folder_path}\")\n",
    "            resize_frames_in_folder(folder_path)\n",
    "\n",
    "# Example usage\n",
    "parent_folder = '/content/raw_data/test'  # Adjust this path to fit video files location where multiple frames folders are stored\n",
    "process_multiple_folders(parent_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stabilize video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def stabilize_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_path}\")\n",
    "        return\n",
    "\n",
    "    # Get frame rate and frame size for the output video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Read first frame\n",
    "    ret, prev = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        ret, curr = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        dx, dy = np.median(flow[..., 0]), np.median(flow[..., 1])\n",
    "\n",
    "        # Transformation matrix\n",
    "        m = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        stabilized = cv2.warpAffine(prev, m, (frame_width, frame_height))\n",
    "\n",
    "        out.write(stabilized)\n",
    "        prev_gray = curr_gray\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Stabilization complete and saved to {output_path}\")\n",
    "\n",
    "def process_videos(input_folder):\n",
    "    # Create output folder next to the input folder\n",
    "    output_folder = os.path.join(input_folder, '../stabilized_videos')\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "\n",
    "    # Process each video in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.mp4'):  # Check for video files\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, 'stabilized_' + filename)\n",
    "            print(f\"Processing {input_path}...\")\n",
    "            stabilize_video(input_path, output_path)\n",
    "\n",
    "#Adjust the path to use\n",
    "input_directory = '/content/raw_data/test'\n",
    "process_videos(input_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subtract background from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def subtract_background_from_video(input_path, output_path):\n",
    "    # Create the background subtractor object\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_path}\")\n",
    "        return\n",
    "\n",
    "    # Prepare to write the processed video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
    "                          (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = back_sub.apply(frame)\n",
    "\n",
    "        # Save the resulting frame to the output video\n",
    "        out.write(fg_mask)\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Background subtraction complete and saved to {output_path}\")\n",
    "\n",
    "def process_videos(input_folder):\n",
    "    # Automatically set the output directory relative to the input folder\n",
    "    output_folder = os.path.join(input_folder, '../processed_videos')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.mp4'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, 'bg_subtracted_' + filename)\n",
    "            print(f\"Processing {input_path}...\")\n",
    "            subtract_background_from_video(input_path, output_path)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_directory = '/path/to/your/input/videos'  # change this to the actual path for videos (the original ones from kaggle)\n",
    "process_videos(input_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
